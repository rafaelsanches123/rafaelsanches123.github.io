I"0<p><img src="https://rafaelsanches123.github.io/assets/arquitetura-hadoop.png" alt="arquitetura-hadoop" style="width: 100%" /></p>

<p>Fala pessoal blz? No post de hoje vamos trocar uma ideia sobre a Arquitetura de Big Data <strong>Hadoop</strong>. E a√≠, bora aprender algo novo?</p>

<h2 id="o-que-√©-hadoop">O que √© Hadoop?</h2>

<p>O Hadoop √© um ecossistema/estrutura de software open source criado para armazenar de forma massiva dados dos mais diversos tipos e executar aplica√ß√µes distribu√≠das (i.e., tarefas ocorrendo ao mesmo tempo) em clusters (i.e., computadores conectados entre si) de hardwares comuns e de baixo custo.</p>

<p>A ideia por traz do Hadoop √© fornecer um ambiente <strong>escal√°vel</strong> no qual, quando voc√™ vai necessitando de mais espa√ßo e poder computacional voc√™ vai adicionando mais m√°quinas ao seu cluster Hadoop.</p>

<p>E importante ressaltar que o Hadoop √© <strong>tolerante a falhas</strong> e por causa disso ele <strong>replica os dados</strong> armazenados no seu sistema de arquivos para evitar que isso aconte√ßa durante o uso de alguma aplica√ß√£o sobre os dados utilizados.</p>

<p>O Hadoop consiste desses <strong>3 componentes core</strong> para o seu funcionamento:</p>

<ul>
  <li><strong>Hadoop Distributed File System</strong> (<strong>HDFS</strong>) ‚Äì √â a camada de armazenamento do Hadoop.</li>
  <li><strong>Map-Reduce</strong> ‚Äì √â a camada de processamento de dados do Hadoop.</li>
  <li><strong>YARN</strong> ‚Äì √â a camada de gerenciamento de recursos do Hadoop.</li>
</ul>

<p>A seguir eu vou falar sobre as 3 camadas/componentes que eu penso quando escuto falar no Hadoop, acredito serem extramente importantes para o funcionamento desse ecossistema.</p>

<h2 id="o-que-√©-o-hdfs">O que √© o HDFS?</h2>

<p>Na <strong>camada de armazenamento</strong> temos o HDFS que √© um sistema de arquivos distribu√≠do, projetado para armazenar arquivos muito grandes, com padr√£o de acesso aos dados streaming (i.e., dados em streaming, s√£o <strong>dados gerados continuamente</strong> por milhares de fontes de dados e.g., <strong>Internet das Coisas</strong>) e batch (i.e., em lote), utilizando clusters de servidores facilmente encontrados no mercado e de baixo ou m√©dio custo.</p>

<p>√â importante ressaltar que o Hadoop n√£o deve ser utilizado para aplica√ß√µes que precisem de acesso r√°pido a um determinado registro e sim para aplica√ß√µes nas quais √© necess√°rio ler uma quantidade massiva (i.e., muito grande) de dados.</p>

<p>Quando utilizamos o Hadoop outra quest√£o que deve ser analisada √© que ele n√£o deve ser utilizado para ler muitos arquivos pequenos, isso ir√° acarretar no mal uso de armazenamento e ir√° gerar um processamento mais lento tendo em vista o overhead de mem√≥ria envolvido.</p>

<p>O HDFS possui o <strong>conceito de blocos</strong>, assim como no sistema Unix, mas seus blocos normalmente t√™m tamanho de <strong>128MB</strong>.  Um arquivo muito grande pode ter blocos armazenados em mais de um local (i.e., sistema de toler√¢ncia a falhas). Com este conceito de blocos de tamanho fixo fica mais f√°cil calcular as necessidades de armazenamento para cada projeto que precise utilizar o seu cluster Hadoop. Essa representa√ß√£o de aloca√ß√£o de recurso no HDFS fica mais clara com o exemplo na Figura 1. Na Figura 1 √© utilizado um arquivo de exemplo com a extens√£o .txt que tem o tamanho de 612 MB. Devido ao tamanho do arquivo ele √© quebrado em 5 partes onde, 4 partes usam 128 MB e somente a ultima parte tem o tamanho 100 MB sendo o menor bloco. Isso ocorre devido ao formato e tamanho do armazenato configurados para o seu ambiente hadoop.</p>

<p><img src="https://rafaelsanches123.github.io/assets/hadoop_hdfs.png" alt="arquitetura-hadoop" style="width: 100%" />
<strong><em>Figura 1</em></strong>: <em>Exemplo de aloca√ß√£o de recursos no HFDS para um arquivo com tamanho de 612 MB - Imagem adaptada de: https://data-flair.training/blogs/data-block/</em></p>

<p>O HDFS possui 2 tipos de n√≥s sendo eles o <strong>Master</strong> (ou <strong>Namenode</strong>) e <strong>Worker</strong> (ou <strong>Datanode</strong>).  O Master armazena informa√ß√µes da distribui√ß√£o de arquivos e os seus respectivos metadados. O Worker armazena os dados propriamente ditos.</p>

<h2 id="mapreduce-e-outras-aplica√ß√µes">MapReduce e Outras Aplica√ß√µes</h2>

<p>Na camada de processamento de dados temos o <strong>MapReduce</strong> que √© um modelo de programa√ß√£o distribu√≠da (i.e., paralela) proposto pelo Google para para facilitar o processamento de grandes volumes de dados (i.e., Big Data).</p>

<p>O modelo de programa√ß√£o MapReduce consiste na constru√ß√£o de um programa formado por duas opera√ß√µes basicas sendo elas o <strong>Map</strong> e o <strong>Reduce</strong>. O processo de Map recebe um par <strong>chave</strong> e <strong>valor</strong> e gera tamb√©m um conjunto intermedi√°rio de dados no formato chave e valor. O processo de reduce √© executado para cada chave intermedi√°ria com todos os conjuntos de valores intermedi√°rios associados √†quela chave combinados. De forma sucinta o processo de map √© usado para encontrar algo, e o processo de reduce √© utilizado para fazer a sumariza√ß√£o do resultado.</p>

<p>Na Figura 2 √© ilustrado o processo de <strong>Map</strong> e <strong>Reduce</strong> em um problema de contagem de letras. Nesse exemplo √© realizada a contagem de quantas vezes alguma letra se repete dentro de um texto qualquer.</p>

<p><img src="https://rafaelsanches123.github.io/assets/hadoop_mapreduce.png" alt="arquitetura-hadoop" style="width: 100%" />
<strong><em>Figura 2</em></strong>: <em>Exemplo de execu√ß√£o do processo de MapReduce sobre um conjunto de dados texto - Imagem adaptada de: https://pt.itbrain.online/tutorial/map_reduce/map_reduce_quick_guide/</em></p>

<p>Voc√™ sabia que o modelo de processamento <strong>MapReduce</strong> √© indicado para problemas mais simples de Big Data. Ele processa os dados em mem√≥ria secund√°rio o que acaba sendo algo lento. Nesse caso o <strong>MapReduce</strong> √© indicado para problemas analiticos onde, o tempo de resposta n√£o precise ser imediato para tomada de decis√£o. O <strong>MapReduce</strong> √© tamb√©m indicado quando sua mem√≥ria primaria √© inferior ao tamanho do dataset que voc√™ precisa processar com seu <strong>Cluster Hadoop</strong>.</p>

<p><strong>Ainda sobre MapReduce, irei fazer um outro post somente sobre isso com c√≥digo para simplificar o conceito de forma mais clara e objetiva.</strong></p>

<h2 id="o-que-√©-o-yarn">O que √© o YARN?</h2>

<p>Na camada de gerenciamento de recursos temos o <strong>Yet Another Resource Negotiator</strong> (<strong>YARN</strong>). O princ√≠pio b√°sico por tr√°s do YARN √© separar o gerenciamento de recursos e a fun√ß√£o de planejamento/monitoramento de tarefas em daemons (i.e., em segundo plano/background) separados.</p>

<p>Na Figura 3 ilustra-se o processo de envio de um job para o cluster hadoop e como o YARN realiza o gerenciamento desse job em rela√ß√£o ao n√≥ master e workers disponiveis no cluster para processar o job que acaba de chegar. A seguir falaremos sobre os recursos gerenciados pelo YARN referentes ao processo ilustrado na Figura 3.</p>

<p><img src="https://rafaelsanches123.github.io/assets/hadoop_yarn.png" alt="arquitetura-hadoop" style="width: 100%" />
<strong><em>Figura 3</em></strong>: <em>Exemplo fluxo de execu√ß√£o realizado pelo gerenciador de recursos YARN - Imagem adaptada de: https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781788999830/5/ch05lvl1sec42/understanding-yarn-architecture</em></p>

<p>No YARN, h√° um <strong>gerenciador de recursos global</strong> (i.e., <strong>ResourceManager</strong>) e um <strong>gerenciador de aplicativos</strong> (i.e., <strong>ApplicationMaster</strong>) por aplicativo. Um aplicativo pode ser uma √∫nica tarefa ou uma DAG de tarefas (i.e., uma tarefa composta por sub-tarefas).</p>

<p>Dentro da estrutura YARN, temos duas daemons sendo elas o <strong>ResourceManager</strong> e <strong>NodeManager</strong>. O ResourceManager gerenncia recursos entre todos os aplicativos concorrentes no sistema. A fun√ß√£o do <strong>NodeManger</strong> √© monitorar o uso de recursos por container e relatar o mesmo ao ResourceManger. Os recursos s√£o como a CPU, mem√≥ria, disco, rede e assim por diante.</p>

<p>O ApplcationMaster negocia recursos com ResourceManager e trabalha com NodeManger para executar e monitorar cada tarefa.</p>

<p>O ResourceManger tem dois componentes importantes sendo eles o <strong>Scheduler</strong> e <strong>ApplicationManager</strong>.</p>

<blockquote>
  <p>Scheduler</p>
</blockquote>

<p>O Scheduler √© o respons√°vel por alocar <strong>recursos</strong> para <strong>v√°rios aplicativos</strong>. Este √© um agendador puro, pois n√£o realiza rastreamento de status para os aplicativos. Tamb√©m n√£o reagenda as tarefas que falham devido a erros de software ou hardware. O agendador aloca os recursos com base nos requisitos dos aplicativos.</p>

<blockquote>
  <p>ApplicationManager</p>
</blockquote>

<p>Func√µes do ApplicationManager:</p>

<ul>
  <li>Aceita o envio de tarefas;</li>
  <li>Negocia o primeiro container para a execu√ß√£o do ApplicationMaster. Um container incorpora elementos como a CPU, mem√≥ria, disco e rede.</li>
  <li>Reinicia o container ApplicationMaster em caso de falha.</li>
</ul>

<p>Fun√ß√µes do ApplicationMaster:</p>

<ul>
  <li>Negocia o container de recursos do Scheduler.</li>
  <li>Rastreia o status do container de recursos.</li>
  <li>Monitora o progresso dos aplicativos.</li>
</ul>

<p>Podemos escalar o YARN por meio de v√°rios n√≥s atr√°vez do recurso <strong>YARN Federation</strong>. Esse recurso nos permite vincular v√°rios clusters YARN em um √∫nico cluster massivo. Isso permite o uso de clusters independentes, agrupados para uma tarefa muito grande (i.e., tamb√©m conhecido como filas de processamento espec√≠ficas).</p>

<h2 id="quais-s√£o-os-desafios-em-usar-o-hadoop">Quais s√£o os desafios em usar o Hadoop?</h2>

<blockquote>
  <p>A programa√ß√£o de MapReduce n√£o √© uma boa solu√ß√£o para todos os problemas</p>
</blockquote>

<p>Ela √© uma boa alternativa para tarefas simples e problemas que podem ser divididos entre unidades independentes, mas n√£o √© eficiente para tarefas de intelig√™ncia anal√≠tica iterativas e interativas. MapReduce foi desenvolvido focado para trabalhar com arquivos. Devido aos n√≥s n√£o se comunicarem diretamente, exceto atrav√©s de opera√ß√µes de map e reduce, algoritmos iterativos precisam de diversas etapas de map e reduce para se completarem. Isso cria muitos arquivos entre as fases de MapReduce e n√£o √© eficiente para computa√ß√£o anal√≠tica avan√ßada.</p>

<blockquote>
  <p>H√° uma lacuna de talento amplamente notada referente aos profissionais de Big Data</p>
</blockquote>

<p>Em pleno ano de 2021 ainda pode ser dif√≠cil encontrar bons programadores iniciantes que tenham habilidades suficientes em Java para serem produtivos usando o modelo MapReduce. Esse √© um dos motivos pelos quais os fornecedores de solu√ß√£o Hadoop est√£o buscando alternativas para incluir tecnologias like SQL (i.e., relacional) em Hadoop. √â muito mais f√°cil encontrar programadores com habilidades em SQL do que em programa√ß√£o MapReduce (i.e., programa√ß√£o distribu√≠da).</p>

<p>Esse √© um bom mercado para se encontrar trabalho pois ainda faltam profissionais capacitados.</p>

<blockquote>
  <p>Gest√£o e governan√ßa de dados completos do √≠nicio ao fim</p>
</blockquote>

<p>O Hadoop n√£o possui ferramentas completas e f√°ceis de usar para o gerenciamento de dados, limpeza de dados, governan√ßa e gest√£o de metadados. Tamb√©m faltam ferramentas para a qualidade e padroniza√ß√£o de dados por ser um ambiente que trabalha com dados complexos em geral.</p>

<p>Para mais detalhes e complementos sobre o Hadoop, voc√™ poder acessar o site do <a href="https://hadoop.apache.org" target="_blank">Apache Hadoop</a> e ler sobre os t√≥picos discutidos nesse post.</p>

<p>Espero ter ajudado voc√™ caro leitor(a) a entender um pouco mais sobre o que √© o Hadoop e como ele funciona, de forma simples, por mais complexo que ele seja. Se voc√™ curtiu esse post, curta e compartilhe com os amigos.</p>
:ET